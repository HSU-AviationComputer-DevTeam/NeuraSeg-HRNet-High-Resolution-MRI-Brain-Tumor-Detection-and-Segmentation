{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7436152,
          "sourceType": "datasetVersion",
          "datasetId": 4327785
        }
      ],
      "dockerImageVersionId": 30636,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Brain Tumor Segmentation (detectron2, mAP@50:76.2)",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "pkdarabi_brain_tumor_image_dataset_semantic_segmentation_path = kagglehub.dataset_download('pkdarabi/brain-tumor-image-dataset-semantic-segmentation')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "_RUe17mGLkE4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used the following methods.\n",
        "\n",
        "* I used a pretrained <b>Mask R-CNN with ResNeXt-101-32x8d for Feature Pyramid Network</b> from detectron2 [1,2]\n",
        "* I have modified the official notebook [3]\n",
        "* I used validation and test sets for testing,\n",
        "\n",
        "## Test Predictions\n",
        "![Screenshot 2024-01-20 at 10.49.00 PM.png](attachment:d15d567c-842d-4d8f-951d-de06b4f85299.png)\n",
        "![Screenshot 2024-01-20 at 10.49.30 PM.png](attachment:2f4a729d-7e4c-4b57-a24b-17e825fb2dfa.png)\n",
        "\n",
        "## References\n",
        "1. Ren, S., He, K., Girshick, R., & Sun, J. (2015). Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks (Version 3). arXiv. https://doi.org/10.48550/ARXIV.1506.01497\n",
        "2. https://detectron2.readthedocs.io/en/latest/\n",
        "3. https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5"
      ],
      "metadata": {
        "id": "yIbDbxT0LkE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os, distutils.core\n",
        "from IPython.display import clear_output\n",
        "\n",
        "!python -m pip install pyyaml==5.1\n",
        "!git clone 'https://github.com/facebookresearch/detectron2'\n",
        "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
        "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
        "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
        "clear_output()"
      ],
      "metadata": {
        "trusted": true,
        "id": "C_OwKgxvLkE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dependencies\n",
        "\n",
        "import torch, detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "print(\"detectron2 version:\", detectron2.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from IPython import display\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# importing detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "\n",
        "SEED = 99\n",
        "THRESHOLD = 0.6"
      ],
      "metadata": {
        "trusted": true,
        "id": "9OJeaVZSLkE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span style=\"color:#e74c3c;\"> Creating </span> Datasets"
      ],
      "metadata": {
        "id": "BPQXXK8dLkE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating coco instances\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "\n",
        "for d in [\"train\", \"valid\",\"test\"]:\n",
        "    register_coco_instances(f\"brain_tumor_{d}\", {},\n",
        "                            f\"../input/brain-tumor-image-dataset-semantic-segmentation/{d}/_annotations.coco.json\",\n",
        "                            f\"../input/brain-tumor-image-dataset-semantic-segmentation/{d}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "J-FvXLVmLkE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples from the training dataset\n",
        "\n",
        "import random\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "my_dataset_train_metadata = MetadataCatalog.get(\"brain_tumor_train\")\n",
        "train_dataset_dicts = DatasetCatalog.get(\"brain_tumor_train\")\n",
        "\n",
        "# A function that creates examples from the dataset\n",
        "def create_random_images(dataset_dict,dataset_metadata, seed, image_scale = 0.7):\n",
        "    np.random.seed(seed)\n",
        "    images = np.random.permutation(dataset_dict)[:2]\n",
        "\n",
        "    fig, axs = plt.subplots(1,2, figsize = (12,6), dpi = 100)\n",
        "    for i in range(2):\n",
        "        im = images[i]\n",
        "        img_link = im['file_name']\n",
        "        img_id = im['image_id']\n",
        "        img = cv2.imread(img_link)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        visualizer = Visualizer(img, metadata= dataset_metadata, scale=image_scale)\n",
        "        vis = visualizer.draw_dataset_dict(im)\n",
        "        final_img = vis.get_image()\n",
        "\n",
        "        axs[i].set_title('image id: ' + str(img_id), fontsize = 10)\n",
        "        axs[i].axis('off')\n",
        "        axs[i].imshow(final_img)"
      ],
      "metadata": {
        "trusted": true,
        "id": "QQgRl4kqLkE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_random_images(train_dataset_dicts, my_dataset_train_metadata, seed = 95, image_scale = 1)\n",
        "create_random_images(train_dataset_dicts, my_dataset_train_metadata, seed = 99, image_scale = 1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "DEjhMSRsLkE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span style=\"color:#e74c3c;\"> Training </span>"
      ],
      "metadata": {
        "id": "F9Ve9mXILkE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "EPOCHS = 3300\n",
        "NUM_CLASSES = 3\n",
        "BASE_LR = 0.0001\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "cfg.DATASETS.TRAIN = (\"brain_tumor_train\")\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = BASE_LR\n",
        "cfg.SOLVER.MAX_ITER = EPOCHS\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# uncomment below to train\n",
        "trainer = DefaultTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "metadata": {
        "trusted": true,
        "id": "jgAN0X0JLkE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model\n",
        "\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = THRESHOLD\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "import pickle\n",
        "with open(\"cfg.pkl\", \"wb\") as f:\n",
        "    pickle.dump(cfg, f)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nRCOaDBnLkE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span style=\"color:#e74c3c;\"> Training </span> Results"
      ],
      "metadata": {
        "id": "l_gLwlnzLkE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# original code from https://eidos-ai.medium.com/training-on-detectron2-with-a-validation-set-and-plot-loss-on-it-to-avoid-overfitting-6449418fbf4e\n",
        "\n",
        "def reading_metrics_from_json(metrics_path):\n",
        "    metrics = []\n",
        "    with open(metrics_path, 'r') as f:\n",
        "        for line in f:\n",
        "            metrics.append(json.loads(line))\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def metric(metrics, specific_metric):\n",
        "    metric = []\n",
        "    for i in range(len(metrics)):\n",
        "        try:\n",
        "            metric.append(metrics[i][specific_metric])\n",
        "        except KeyError:\n",
        "            pass\n",
        "    return metric"
      ],
      "metadata": {
        "trusted": true,
        "id": "ao-s4kw4LkE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_metrics = reading_metrics_from_json('/kaggle/working/output/metrics.json')\n",
        "\n",
        "iters = metric(train_metrics, 'iteration')\n",
        "total_loss = metric(train_metrics, 'total_loss')\n",
        "cls_acc = metric(train_metrics, 'fast_rcnn/cls_accuracy')\n",
        "loss_mask = metric(train_metrics, 'loss_mask')\n",
        "loss_box_reg = metric(train_metrics, 'loss_box_reg')\n",
        "\n",
        "\n",
        "# checking metric lengths\n",
        "if len(iters) == len(total_loss) == len(cls_acc) == len(loss_mask) == len(loss_box_reg):\n",
        "    pass\n",
        "else:\n",
        "    iters = iters[:-1]"
      ],
      "metadata": {
        "trusted": true,
        "id": "gOnWbvGvLkE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,4, figsize = (17, 4), dpi = 120)\n",
        "\n",
        "\n",
        "axs[0].grid(linestyle = 'dashdot')\n",
        "axs[0].plot(iters, loss_box_reg)\n",
        "axs[0].set_xlabel('epochs', fontsize = 10)\n",
        "axs[0].set_title('Loss Box Regression', fontsize = 10)\n",
        "tit0 = ' (the last value {0:.4f})'.format(loss_box_reg[-1])\n",
        "axs[0].set_title('Loss Box Regression ' + tit0, fontsize = 10, color = 'red')\n",
        "\n",
        "axs[1].grid(linestyle = 'dashdot')\n",
        "axs[1].plot(iters, cls_acc)\n",
        "axs[1].set_xlabel('epochs', fontsize = 10)\n",
        "tit1 = ' (the last value {0:.3f})'.format(cls_acc[-1])\n",
        "axs[1].set_title('Class Accuracy ' + tit1, fontsize = 10, color = 'red')\n",
        "\n",
        "axs[2].grid(linestyle = 'dashdot')\n",
        "axs[2].plot(iters, total_loss)\n",
        "axs[2].set_xlabel('epochs', fontsize = 10)\n",
        "tit2 = ' (the last value {0:.4f})'.format(total_loss[-1])\n",
        "axs[2].set_title('Total Loss ' + tit2, fontsize = 10, color = 'red')\n",
        "\n",
        "axs[3].grid(linestyle = 'dashdot')\n",
        "axs[3].plot(iters, loss_mask)\n",
        "axs[3].set_xlabel('epochs', fontsize = 10)\n",
        "axs[3].set_title('Mask Loss', fontsize = 10, color = 'red')"
      ],
      "metadata": {
        "trusted": true,
        "id": "bbTg4HKrLkE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span style=\"color:#e74c3c;\"> Validation </span> Predictions"
      ],
      "metadata": {
        "id": "aEGKzz9JLkE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"brain_tumor_valid\", False, output_dir=\"./output/\")\n",
        "test_loader = build_detection_test_loader(cfg, \"brain_tumor_valid\")\n",
        "inference_on_dataset(trainer.model, test_loader, evaluator)"
      ],
      "metadata": {
        "trusted": true,
        "id": "32505Ju8LkE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dataset_test_metadata = MetadataCatalog.get(\"brain_tumor_valid\")\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = DatasetCatalog.get(\"brain_tumor_valid\")\n",
        "\n",
        "\n",
        "# A function for plotting an original image's bbox and predicted bbox\n",
        "def create_predictions(dataset_dict, dataset_metadata, seed, image_scale = 0.8):\n",
        "    np.random.seed(seed=seed)\n",
        "    images = np.random.permutation(dataset_dict)[:3]\n",
        "\n",
        "    fig, axs = plt.subplots(3,2, figsize = (20,20), dpi = 120)\n",
        "\n",
        "    for i in range(3):\n",
        "        im = images[i]\n",
        "        img_link = im['file_name']\n",
        "        img_id = im['image_id']\n",
        "        img = cv2.imread(img_link)\n",
        "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "        visualizer1 = Visualizer(img, metadata= dataset_metadata, scale=image_scale)\n",
        "\n",
        "        vis_original = visualizer1.draw_dataset_dict(im)\n",
        "        original_bbox = vis_original.get_image()\n",
        "\n",
        "        visualizer2 = Visualizer(img[:, :, ::-1], metadata= dataset_metadata, scale=image_scale, instance_mode=ColorMode.IMAGE_BW)\n",
        "        outputs = predictor(img)\n",
        "        out = visualizer2.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "        out_img = cv2.cvtColor(out.get_image(), cv2.COLOR_BGR2RGB)\n",
        "        final_bbox = cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        axs[i][0].set_title('original bbox (id: ' + str(img_id) +')', fontsize = 20)\n",
        "        axs[i][0].axis('off')\n",
        "        axs[i][0].imshow(original_bbox)\n",
        "\n",
        "        axs[i][1].set_title('predicted bbox (id: ' + str(img_id) +')', fontsize = 20, color = 'red')\n",
        "        axs[i][1].axis('off')\n",
        "        axs[i][1].imshow(final_bbox[:, :, ::-1])\n",
        "\n",
        "    fig.tight_layout()"
      ],
      "metadata": {
        "trusted": true,
        "id": "QTyj89uzLkE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_predictions(dataset_dicts,my_dataset_test_metadata, seed = 421, image_scale = 1)\n",
        "create_predictions(dataset_dicts,my_dataset_test_metadata, seed = 83, image_scale = 1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "fIdOb-3iLkE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <span style=\"color:#e74c3c;\"> Test </span> Predictions"
      ],
      "metadata": {
        "id": "2-dwVLxvLkE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"brain_tumor_test\", False, output_dir=\"./output/\")\n",
        "test_loader = build_detection_test_loader(cfg, \"brain_tumor_test\")\n",
        "inference_on_dataset(trainer.model, test_loader, evaluator)\n",
        "\n",
        "\n",
        "my_dataset_test_metadata = MetadataCatalog.get(\"brain_tumor_test\")\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = DatasetCatalog.get(\"brain_tumor_test\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "GTewgi0kLkE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_predictions(dataset_dicts,my_dataset_test_metadata, seed = 154, image_scale = 1)\n",
        "create_predictions(dataset_dicts,my_dataset_test_metadata, seed = 51, image_scale = 1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "juVO9raJLkE-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}