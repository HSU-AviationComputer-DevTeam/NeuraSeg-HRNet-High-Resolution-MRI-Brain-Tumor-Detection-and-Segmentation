{
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "image segmentation"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7436152,
          "sourceType": "datasetVersion",
          "datasetId": 4327785
        },
        {
          "sourceId": 89375,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 74978,
          "modelId": 99700
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "pkdarabi_brain_tumor_image_dataset_semantic_segmentation_path = kagglehub.dataset_download('pkdarabi/brain-tumor-image-dataset-semantic-segmentation')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "n65qaXAkLvBc"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n"
      ],
      "metadata": {
        "id": "Vh_mCEBI7Vj6",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:22.99246Z",
          "iopub.execute_input": "2024-08-05T12:54:22.992801Z",
          "iopub.status.idle": "2024-08-05T12:54:35.352189Z",
          "shell.execute_reply.started": "2024-08-05T12:54:22.992774Z",
          "shell.execute_reply": "2024-08-05T12:54:35.351432Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:35.353676Z",
          "iopub.execute_input": "2024-08-05T12:54:35.354177Z",
          "iopub.status.idle": "2024-08-05T12:54:35.542046Z",
          "shell.execute_reply.started": "2024-08-05T12:54:35.354151Z",
          "shell.execute_reply": "2024-08-05T12:54:35.540663Z"
        },
        "trusted": true,
        "id": "y48oAXMhLvBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading any random image\n",
        "train_path  = '/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/train/'\n",
        "test_path = '/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/test/'\n",
        "val_path  = '/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/valid/'"
      ],
      "metadata": {
        "id": "QAbEJ2Dt9bkJ",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:35.543546Z",
          "iopub.execute_input": "2024-08-05T12:54:35.543941Z",
          "iopub.status.idle": "2024-08-05T12:54:35.558443Z",
          "shell.execute_reply.started": "2024-08-05T12:54:35.543905Z",
          "shell.execute_reply": "2024-08-05T12:54:35.557628Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = [image for image in os.listdir(train_path) if image[-3:] =='jpg' ]\n",
        "test_images = [image for image in os.listdir(test_path) if image[-3:] =='jpg' ]\n",
        "val_images = [image for image in os.listdir(val_path) if image[-3:] =='jpg' ]\n",
        "len(train_images),len(test_images),len(val_images)"
      ],
      "metadata": {
        "id": "xad7JnVj-zEA",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:35.560968Z",
          "iopub.execute_input": "2024-08-05T12:54:35.561345Z",
          "iopub.status.idle": "2024-08-05T12:54:35.748147Z",
          "shell.execute_reply.started": "2024-08-05T12:54:35.561313Z",
          "shell.execute_reply": "2024-08-05T12:54:35.747326Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "train_annotations = glob.glob(os.path.join(train_path, '*.json'))\n",
        "test_annotations = glob.glob(os.path.join(test_path, '*.json'))\n",
        "val_annotations = glob.glob(os.path.join(val_path, '*.json'))\n"
      ],
      "metadata": {
        "id": "AvwEWmrW_gqA",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:35.749113Z",
          "iopub.execute_input": "2024-08-05T12:54:35.74938Z",
          "iopub.status.idle": "2024-08-05T12:54:35.758928Z",
          "shell.execute_reply.started": "2024-08-05T12:54:35.749358Z",
          "shell.execute_reply": "2024-08-05T12:54:35.75807Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "LFWg6sH-BFon",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:35.759831Z",
          "iopub.execute_input": "2024-08-05T12:54:35.760073Z",
          "iopub.status.idle": "2024-08-05T12:54:35.766044Z",
          "shell.execute_reply.started": "2024-08-05T12:54:35.760051Z",
          "shell.execute_reply": "2024-08-05T12:54:35.765223Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_annotations = json.load(open(train_annotations[0]))\n",
        "test_annotations = json.load(open(test_annotations[0]))\n",
        "val_annotations = json.load(open(val_annotations[0]))"
      ],
      "metadata": {
        "id": "1Rlp6M8_BDCY",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:35.767119Z",
          "iopub.execute_input": "2024-08-05T12:54:35.767438Z",
          "iopub.status.idle": "2024-08-05T12:54:35.804185Z",
          "shell.execute_reply.started": "2024-08-05T12:54:35.767408Z",
          "shell.execute_reply": "2024-08-05T12:54:35.803515Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_annotations['annotations']),len(test_annotations['annotations']),len(val_annotations['annotations']),"
      ],
      "metadata": {
        "id": "ehAdAtlgBEZe",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:35.805203Z",
          "iopub.execute_input": "2024-08-05T12:54:35.805488Z",
          "iopub.status.idle": "2024-08-05T12:54:35.811219Z",
          "shell.execute_reply.started": "2024-08-05T12:54:35.805466Z",
          "shell.execute_reply": "2024-08-05T12:54:35.81031Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def visualize_random_images(n=5):\n",
        "  # select n random images\n",
        "  # use cv and plt to show these images\n",
        "  indices = np.random.randint(0, len(train_annotations['images']), size=n)\n",
        "\n",
        "  images =[train_annotations['images'][i] for i in indices ]\n",
        "\n",
        "  annotations = [train_annotations['annotations'][i] for i in indices ]\n",
        "  j=1\n",
        "  plt.figure(figsize=(12, 4 * 2 * n))\n",
        "  for img,ann in zip(images,annotations):\n",
        "    plt.subplot(n,3,j)\n",
        "    j+=1\n",
        "    image = cv2.imread(train_path + img['file_name'])\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.imshow(image)\n",
        "    # create masked images from annotations\n",
        "    segmentation = ann['segmentation']\n",
        "    segmentation = np.array(segmentation[0], dtype=np.int32).reshape(-1, 2)\n",
        "\n",
        "    cv2.polylines(image, [segmentation], isClosed=True, color=(0, 255, 0), thickness=2)  # Green color with thickness 2\n",
        "\n",
        "    plt.subplot(n,3,j)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    j+=1\n",
        "    mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
        "    cv2.fillPoly(mask, [segmentation], color=1)\n",
        "    plt.subplot(n,3,j)\n",
        "\n",
        "    plt.imshow(mask,cmap='gray')\n",
        "    j+=1\n",
        "\n",
        "visualize_random_images()"
      ],
      "metadata": {
        "id": "5CGsOi0XBmVi",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:35.812434Z",
          "iopub.execute_input": "2024-08-05T12:54:35.812834Z",
          "iopub.status.idle": "2024-08-05T12:54:39.357545Z",
          "shell.execute_reply.started": "2024-08-05T12:54:35.812804Z",
          "shell.execute_reply": "2024-08-05T12:54:39.356607Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create binary mask for all images"
      ],
      "metadata": {
        "id": "9tBLDBERLUR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _train_masks():\n",
        "    print('train masks')\n",
        "    mask_dir = '/kaggle/working/train_masks/'\n",
        "    os.makedirs(mask_dir, exist_ok=True)\n",
        "    totalImages = len(train_annotations['images'])\n",
        "    done = 0\n",
        "    for img,ann in zip(train_annotations['images'],train_annotations['annotations']):\n",
        "        path = train_path + img['file_name']\n",
        "        mask_path = mask_dir + img['file_name']\n",
        "        # load image in open cv\n",
        "        image = cv2.imread(path)\n",
        "        segmentation = ann['segmentation']\n",
        "        segmentation = np.array(segmentation[0], dtype=np.int32).reshape(-1, 2)\n",
        "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
        "        cv2.fillPoly(mask, [segmentation], color=(255,255,255))\n",
        "        cv2.imwrite(mask_path, mask)\n",
        "        done+=1\n",
        "        print(f\"train  {done} / {totalImages} \")\n",
        "\n",
        "def _test_masks():\n",
        "    print('test masks')\n",
        "\n",
        "    totalImages = len(test_annotations['images'])\n",
        "    done = 0\n",
        "    mask_dir = '/kaggle/working/test_masks/'\n",
        "    os.makedirs(mask_dir, exist_ok=True)\n",
        "\n",
        "    for img,ann in zip(test_annotations['images'],test_annotations['annotations']):\n",
        "        path = test_path + img['file_name']\n",
        "        mask_path = mask_dir + img['file_name']\n",
        "        # load image in open cv\n",
        "        image = cv2.imread(path)\n",
        "        segmentation = ann['segmentation']\n",
        "        segmentation = np.array(segmentation[0], dtype=np.int32).reshape(-1, 2)\n",
        "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
        "        cv2.fillPoly(mask, [segmentation], color=(255,255,255))\n",
        "        cv2.imwrite(mask_path, mask)\n",
        "        done+=1\n",
        "\n",
        "        print(f\"test  {done} / {totalImages} \")\n",
        "\n",
        "\n",
        "def _val_masks():\n",
        "    print('val masks')\n",
        "    totalImages = len(val_annotations['images'])\n",
        "    done = 0\n",
        "    mask_dir = '/kaggle/working/val_masks/'\n",
        "    os.makedirs(mask_dir, exist_ok=True)\n",
        "\n",
        "    for img,ann in zip(val_annotations['images'],val_annotations['annotations']):\n",
        "        path = val_path + img['file_name']\n",
        "        mask_path = mask_dir + img['file_name']\n",
        "        # load image in open cv\n",
        "        image = cv2.imread(path)\n",
        "        segmentation = ann['segmentation']\n",
        "        segmentation = np.array(segmentation[0], dtype=np.int32).reshape(-1, 2)\n",
        "        mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)\n",
        "        cv2.fillPoly(mask, [segmentation], color=(255,255,255))\n",
        "        cv2.imwrite(mask_path, mask)\n",
        "        done+=1\n",
        "        print(f\"val  {done} / {totalImages} \")\n",
        "\n",
        "\n",
        "from threading import Thread\n",
        "def make_masks():\n",
        "  threads = []\n",
        "  threads.append( Thread(target=_train_masks))\n",
        "\n",
        "  threads.append( Thread(target=_test_masks))\n",
        "\n",
        "  threads.append( Thread(target=_val_masks))\n",
        "  for t in threads:\n",
        "    t.start()\n",
        "  for t in threads:\n",
        "    t.join()\n",
        "  print('complete')\n",
        "  return\n",
        "\n",
        "make_masks()\n"
      ],
      "metadata": {
        "id": "W7E6nfVIDIBv",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:39.362184Z",
          "iopub.execute_input": "2024-08-05T12:54:39.362574Z",
          "iopub.status.idle": "2024-08-05T12:54:50.54596Z",
          "shell.execute_reply.started": "2024-08-05T12:54:39.362546Z",
          "shell.execute_reply": "2024-08-05T12:54:50.544976Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load and split data"
      ],
      "metadata": {
        "id": "Eb3hT4z8U40m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    target_size = (512, 512)\n",
        "    train_mask_dir = '/kaggle/working/train_masks/'\n",
        "    X_train =  [cv2.resize(cv2.imread(train_path + image['file_name']),target_size) for image in train_annotations['images']]\n",
        "    y_train = [cv2.resize(cv2.imread(train_mask_dir + image['file_name'],cv2.IMREAD_GRAYSCALE),target_size ) for image in train_annotations['images']]\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.expand_dims(np.array(y_train), axis=-1)\n",
        "\n",
        "    X_train = X_train.astype('float32') / 255.0\n",
        "    y_train = y_train.astype('float32') / 255.0\n",
        "    y_train = (y_train > 0.5).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    val_mask_dir = '/kaggle/working/val_masks/'\n",
        "\n",
        "    X_val =  [cv2.resize(cv2.imread(val_path + image['file_name']),target_size) for image in val_annotations['images']]\n",
        "    y_val = [cv2.resize(cv2.imread(val_mask_dir + image['file_name'],cv2.IMREAD_GRAYSCALE),target_size) for image in val_annotations['images']]\n",
        "    X_val = np.array(X_val)\n",
        "    y_val = np.expand_dims(np.array(y_val), axis=-1)\n",
        "\n",
        "\n",
        "\n",
        "    X_val = X_val.astype('float32') / 255.0\n",
        "    y_val = y_val.astype('float32') / 255.0\n",
        "    y_val = (y_val > 0.5).astype(np.float32)\n",
        "\n",
        "\n",
        "\n",
        "    return X_train,y_train,X_val,y_val\n",
        "\n",
        "def load_test_data():\n",
        "    target_size = (512, 512)\n",
        "\n",
        "    test_mask_dir = '/kaggle/working/test_masks/'\n",
        "    X_test =  [cv2.resize(cv2.imread(test_path + image['file_name']),target_size) for image in test_annotations['images']]\n",
        "    y_test = [cv2.resize(cv2.imread(test_mask_dir + image['file_name'],cv2.IMREAD_GRAYSCALE),target_size) for image in test_annotations['images']]\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.expand_dims(np.array(y_test), axis=-1)\n",
        "\n",
        "\n",
        "    X_test = X_test.astype('float32') / 255.0\n",
        "    y_test = y_test.astype('float32') / 255.0\n",
        "    y_test = (y_test > 0.5).astype(np.float32)\n",
        "    return X_test,y_test\n"
      ],
      "metadata": {
        "id": "6QbSKt1eW_0r",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:50.547414Z",
          "iopub.execute_input": "2024-08-05T12:54:50.547745Z",
          "iopub.status.idle": "2024-08-05T12:54:50.562569Z",
          "shell.execute_reply.started": "2024-08-05T12:54:50.547717Z",
          "shell.execute_reply": "2024-08-05T12:54:50.56161Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,y_train,X_val,y_val = load_data()\n"
      ],
      "metadata": {
        "id": "R8fNBKwnUCb8",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:54:50.563793Z",
          "iopub.execute_input": "2024-08-05T12:54:50.564059Z",
          "iopub.status.idle": "2024-08-05T12:55:04.390214Z",
          "shell.execute_reply.started": "2024-08-05T12:54:50.564036Z",
          "shell.execute_reply": "2024-08-05T12:55:04.389449Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape , y_train.shape  ,X_val.shape ,y_val.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:04.391328Z",
          "iopub.execute_input": "2024-08-05T12:55:04.391614Z",
          "iopub.status.idle": "2024-08-05T12:55:04.398237Z",
          "shell.execute_reply.started": "2024-08-05T12:55:04.391591Z",
          "shell.execute_reply": "2024-08-05T12:55:04.397446Z"
        },
        "trusted": true,
        "id": "DfWym2KkLvBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define Unet model"
      ],
      "metadata": {
        "id": "CSJ3d9v4PLLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-7):\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dice_coefficient(y_true, y_pred)\n",
        "    return loss\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:04.399597Z",
          "iopub.execute_input": "2024-08-05T12:55:04.400195Z",
          "iopub.status.idle": "2024-08-05T12:55:04.407189Z",
          "shell.execute_reply.started": "2024-08-05T12:55:04.400164Z",
          "shell.execute_reply": "2024-08-05T12:55:04.406422Z"
        },
        "trusted": true,
        "id": "H4d_GNAPLvBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def convBlock(inputs,filters):\n",
        "    c1 = layers.Conv2D(filters, kernel_size = (3,3), padding = \"same\")(inputs)\n",
        "    c1 = layers.BatchNormalization()(c1)\n",
        "    c1 = layers.ReLU()(c1)\n",
        "\n",
        "    # Taking first input and implementing the second conv block\n",
        "    c2 = layers.Conv2D(filters, kernel_size = (3,3), padding = \"same\")(c1)\n",
        "    c2 = layers.BatchNormalization()(c2)\n",
        "    c2 = layers.ReLU()(c2)\n",
        "\n",
        "    return c2\n",
        "\n",
        "\n",
        "def encoderBlock(inputs,filters):\n",
        "    c = convBlock(inputs, filters)\n",
        "    m = layers.MaxPooling2D(strides = (2,2))(c)\n",
        "    return c, m\n",
        "\n",
        "\n",
        "def decoderBlock(inputs, skip, filters=64):\n",
        "    u = layers.Conv2DTranspose(filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
        "    skip = layers.Concatenate()([u, skip])\n",
        "    out = convBlock(skip, filters)\n",
        "    return out\n",
        "\n",
        "\n",
        "def uNet(image_size):\n",
        "    inputs = layers.Input(image_size)\n",
        "\n",
        "    # Construct the encoder blocks and increasing the filters by a factor of 2\n",
        "    skip1, encoder_1 = encoderBlock(inputs, 64)\n",
        "    skip2, encoder_2 = encoderBlock(encoder_1, 128)\n",
        "    skip3, encoder_3 = encoderBlock(encoder_2, 256)\n",
        "    skip4, encoder_4 = encoderBlock(encoder_3, 512)\n",
        "\n",
        "    # Preparing the next block\n",
        "    conv_block = convBlock(encoder_4, 1024)\n",
        "\n",
        "    # Construct the decoder blocks and decreasing the filters by a factor of 2\n",
        "    decoder_1 = decoderBlock(conv_block, skip4, 512)\n",
        "    decoder_2 = decoderBlock(decoder_1, skip3, 256)\n",
        "    decoder_3 = decoderBlock(decoder_2, skip2, 128)\n",
        "    decoder_4 = decoderBlock(decoder_3, skip1, 64)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(decoder_4)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "5DiuhGPxLt2P",
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:04.408289Z",
          "iopub.execute_input": "2024-08-05T12:55:04.408595Z",
          "iopub.status.idle": "2024-08-05T12:55:04.445654Z",
          "shell.execute_reply.started": "2024-08-05T12:55:04.408572Z",
          "shell.execute_reply": "2024-08-05T12:55:04.444899Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy(model):\n",
        "    X_test,y_test = load_test_data()\n",
        "    batch_size = 2\n",
        "    predictions = model.predict(X_test, batch_size=batch_size)\n",
        "\n",
        "    # Reshape predictions if necessary (assuming single-channel masks)\n",
        "    y_pred = np.squeeze(predictions)\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
        "\n",
        "    threshold = 0.5\n",
        "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
        "\n",
        "    # Calculate pixel-wise accuracy\n",
        "    accuracy = np.mean(y_pred_binary == y_test)\n",
        "\n",
        "    dice_coefficient_score = dice_coefficient(y_test, y_pred)\n",
        "    dice_loss_score = dice_loss(y_test, y_pred)\n",
        "    print(f\"Pixel-wise Accuracy: {accuracy:.4f}\")\n",
        "    print(f'Dice Coefficient: {dice_coefficient_score:.4f}')\n",
        "    print(f'Dice Loss: {dice_loss_score:.4f}')\n",
        "    X_test,y_test = 0,0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:04.446754Z",
          "iopub.execute_input": "2024-08-05T12:55:04.447085Z",
          "iopub.status.idle": "2024-08-05T12:55:04.453643Z",
          "shell.execute_reply.started": "2024-08-05T12:55:04.447056Z",
          "shell.execute_reply": "2024-08-05T12:55:04.452774Z"
        },
        "trusted": true,
        "id": "nWDF9fj9LvBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Model"
      ],
      "metadata": {
        "id": "G0-MqDk5LvBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (512,512,3)\n",
        "model = uNet(input_shape)\n",
        "model.summary()\n",
        "model.load_weights('/kaggle/input/brain_unet/keras/default/1/brain_tumor_unet.weights.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:04.454803Z",
          "iopub.execute_input": "2024-08-05T12:55:04.455117Z",
          "iopub.status.idle": "2024-08-05T12:55:06.684087Z",
          "shell.execute_reply.started": "2024-08-05T12:55:04.455089Z",
          "shell.execute_reply": "2024-08-05T12:55:06.683311Z"
        },
        "trusted": true,
        "id": "rAGVYXv6LvBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_lr = 1e-4\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(optimizer = Adam(learning_rate = initial_lr),loss = dice_loss,metrics=['accuracy',dice_coefficient])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:06.685214Z",
          "iopub.execute_input": "2024-08-05T12:55:06.68554Z",
          "iopub.status.idle": "2024-08-05T12:55:06.701371Z",
          "shell.execute_reply.started": "2024-08-05T12:55:06.685514Z",
          "shell.execute_reply": "2024-08-05T12:55:06.700656Z"
        },
        "trusted": true,
        "id": "CCO49AQ0LvBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saved Weights accuracy\n"
      ],
      "metadata": {
        "id": "AF3bKDjOLvBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:06.702398Z",
          "iopub.execute_input": "2024-08-05T12:55:06.702672Z",
          "iopub.status.idle": "2024-08-05T12:55:40.841529Z",
          "shell.execute_reply.started": "2024-08-05T12:55:06.702649Z",
          "shell.execute_reply": "2024-08-05T12:55:40.840553Z"
        },
        "trusted": true,
        "id": "PLQpy-kFLvBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def predict(image_path, model, threshold=0.5):\n",
        "    # Read and preprocess the image\n",
        "    image = cv2.imread(image_path)\n",
        "    print(\"Original Image Shape:\", image.shape)\n",
        "\n",
        "    # Resize the image to match model's expected sizing\n",
        "    resized_image = cv2.resize(image, (512, 512))\n",
        "    print(\"Resized Image Shape:\", resized_image.shape)\n",
        "\n",
        "    # Expand dimensions to match the batch size used by the model\n",
        "    input_image = np.expand_dims(resized_image, axis=0)\n",
        "\n",
        "    # Preprocess input (normalize to [0, 1] range)\n",
        "    input_image = input_image.astype('float32') / 255.0\n",
        "\n",
        "    # Perform prediction\n",
        "    pred_mask = model.predict(input_image)\n",
        "\n",
        "    # Apply threshold to prediction mask\n",
        "    pred_mask[pred_mask >= threshold] = 1  # set values >= threshold to 1 (foreground)\n",
        "    pred_mask[pred_mask < threshold] = 0   # set values < threshold to 0 (background)\n",
        "\n",
        "    # If your model outputs probabilities, you might need to squeeze the mask\n",
        "    pred_mask = np.squeeze(pred_mask, axis=0)\n",
        "\n",
        "    # Count number of pixels where mask is 1 (foreground)\n",
        "    num_pixels = np.count_nonzero(pred_mask)\n",
        "    print(\"shape mask\",pred_mask.shape)\n",
        "    return pred_mask\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'model' is your trained model and 'image_path' is the path to your image\n",
        "# pred_mask, num_pixels = predict(image_path, model)\n",
        "# print(\"Number of foreground pixels:\", num_pixels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:40.84285Z",
          "iopub.execute_input": "2024-08-05T12:55:40.843217Z",
          "iopub.status.idle": "2024-08-05T12:55:40.851619Z",
          "shell.execute_reply.started": "2024-08-05T12:55:40.843184Z",
          "shell.execute_reply": "2024-08-05T12:55:40.850707Z"
        },
        "trusted": true,
        "id": "Vu6TCzVkLvBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def test_random_images(n=5):\n",
        "  # select n random images\n",
        "  # use cv and plt to show these images\n",
        "    test_mask_dir = '/kaggle/working/test_masks/'\n",
        "\n",
        "    indices = np.random.randint(0, len(test_annotations['images']), size=n)\n",
        "\n",
        "    images =[test_annotations['images'][i] for i in indices ]\n",
        "\n",
        "    annotations = [test_annotations['annotations'][i] for i in indices ]\n",
        "    j=1\n",
        "    plt.figure(figsize=(12, 4 * 2 * n))\n",
        "    for img,ann in zip(images,annotations):\n",
        "        plt.subplot(n,3,j)\n",
        "        j+=1\n",
        "        image = cv2.imread(test_path + img['file_name'])\n",
        "        plt.imshow(image)\n",
        "        plt.title(\"Input\")\n",
        "        mask = predict(test_path + img['file_name'],model)\n",
        "#         print(mask.shape)\n",
        "\n",
        "        result_image = np.zeros((512, 512,1), dtype=np.uint8)\n",
        "\n",
        "        result_image[mask == 1] = 255\n",
        "\n",
        "        true_mask = cv2.imread(test_mask_dir + img['file_name'])\n",
        "        plt.subplot(n,3,j)\n",
        "        j+=1\n",
        "        plt.imshow(true_mask)\n",
        "        plt.title(\"true_mask\")\n",
        "\n",
        "        plt.subplot(n,3,j)\n",
        "        j+=1\n",
        "        plt.imshow(result_image,cmap='gray')\n",
        "        plt.title(\"Prediction\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_random_images()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:40.852683Z",
          "iopub.execute_input": "2024-08-05T12:55:40.852998Z",
          "iopub.status.idle": "2024-08-05T12:55:45.177092Z",
          "shell.execute_reply.started": "2024-08-05T12:55:40.852975Z",
          "shell.execute_reply": "2024-08-05T12:55:45.176185Z"
        },
        "trusted": true,
        "id": "63PL04QdLvBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retraining the model"
      ],
      "metadata": {
        "id": "IaLRpsJ5LvBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss',\n",
        "                                   factor=0.5,\n",
        "                                   patience=5,\n",
        "                                   verbose=1,\n",
        "                                   mode='min',\n",
        "                                   cooldown=3,\n",
        "                                   min_lr=1e-10)\n",
        "\n",
        "\n",
        "callbacks_list = [ reduceLROnPlat]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T12:55:45.178127Z",
          "iopub.execute_input": "2024-08-05T12:55:45.178445Z",
          "iopub.status.idle": "2024-08-05T12:55:45.184565Z",
          "shell.execute_reply.started": "2024-08-05T12:55:45.178411Z",
          "shell.execute_reply": "2024-08-05T12:55:45.183709Z"
        },
        "trusted": true,
        "id": "OazBwKQZLvBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# Now fit your model\n",
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=2,\n",
        "    callbacks=callbacks_list\n",
        ")"
      ],
      "metadata": {
        "id": "yLYQo4YZWTMb",
        "execution": {
          "iopub.status.busy": "2024-08-05T13:05:07.107123Z",
          "iopub.execute_input": "2024-08-05T13:05:07.107522Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('brain_tumor_unet.weights.h5')\n",
        "\n"
      ],
      "metadata": {
        "id": "QbVEowFrWeBL",
        "execution": {
          "iopub.status.busy": "2024-08-05T13:02:21.69879Z",
          "iopub.execute_input": "2024-08-05T13:02:21.699169Z",
          "iopub.status.idle": "2024-08-05T13:02:22.588806Z",
          "shell.execute_reply.started": "2024-08-05T13:02:21.699143Z",
          "shell.execute_reply": "2024-08-05T13:02:22.587971Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrained Weights Metrics"
      ],
      "metadata": {
        "id": "UMriXFtfLvBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'history' is the History object returned by model.fit()\n",
        "def plot_training_history(history):\n",
        "    # Extract metrics from the history object\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "    dice = history.history['dice_coefficient']\n",
        "    val_dice = history.history['val_dice_coefficient']\n",
        "\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    # Plot Loss\n",
        "    plt.figure(figsize=(14, 4))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(epochs, loss,  label='Training loss')\n",
        "    plt.plot(epochs, val_loss,  label='Validation loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(epochs, accuracy, label='Training accuracy')\n",
        "    plt.plot(epochs, val_accuracy, label='Validation accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Dice Coefficient\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(epochs, dice,  label='Training Dice')\n",
        "    plt.plot(epochs, val_dice, label='Validation Dice')\n",
        "    plt.title('Training and Validation Dice Coefficient')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Dice Coefficient')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T13:03:50.996344Z",
          "iopub.execute_input": "2024-08-05T13:03:50.996753Z",
          "iopub.status.idle": "2024-08-05T13:03:51.851235Z",
          "shell.execute_reply.started": "2024-08-05T13:03:50.996722Z",
          "shell.execute_reply": "2024-08-05T13:03:51.850322Z"
        },
        "trusted": true,
        "id": "Tee8nR_WLvBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_random_images()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T13:02:23.446317Z",
          "iopub.execute_input": "2024-08-05T13:02:23.44756Z",
          "iopub.status.idle": "2024-08-05T13:02:28.077725Z",
          "shell.execute_reply.started": "2024-08-05T13:02:23.447527Z",
          "shell.execute_reply": "2024-08-05T13:02:28.076855Z"
        },
        "trusted": true,
        "id": "5RTS9A2FLvBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Model"
      ],
      "metadata": {
        "id": "637GmOJ4LvBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T13:02:28.07886Z",
          "iopub.execute_input": "2024-08-05T13:02:28.079153Z",
          "iopub.status.idle": "2024-08-05T13:02:28.083696Z",
          "shell.execute_reply.started": "2024-08-05T13:02:28.079128Z",
          "shell.execute_reply": "2024-08-05T13:02:28.082762Z"
        },
        "trusted": true,
        "id": "H0cYwDIHLvBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/kaggle/input/brain-tumor-image-dataset-semantic-segmentation/test/'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T13:02:28.088588Z",
          "iopub.execute_input": "2024-08-05T13:02:28.088865Z",
          "iopub.status.idle": "2024-08-05T13:02:28.093253Z",
          "shell.execute_reply.started": "2024-08-05T13:02:28.088841Z",
          "shell.execute_reply": "2024-08-05T13:02:28.092309Z"
        },
        "trusted": true,
        "id": "_6shBcmJLvBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import json\n",
        "test_annotations = glob.glob(os.path.join(test_path, '*.json'))\n",
        "test_annotations = json.load(open(test_annotations[0]))\n",
        "len(test_annotations['annotations'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T13:02:28.094508Z",
          "iopub.execute_input": "2024-08-05T13:02:28.094771Z",
          "iopub.status.idle": "2024-08-05T13:02:28.112356Z",
          "shell.execute_reply.started": "2024-08-05T13:02:28.094748Z",
          "shell.execute_reply": "2024-08-05T13:02:28.111536Z"
        },
        "trusted": true,
        "id": "s8woHQ_3LvBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Metrics"
      ],
      "metadata": {
        "id": "RvFBZixWLvBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-05T13:02:28.113379Z",
          "iopub.execute_input": "2024-08-05T13:02:28.113633Z",
          "iopub.status.idle": "2024-08-05T13:02:42.154722Z",
          "shell.execute_reply.started": "2024-08-05T13:02:28.113612Z",
          "shell.execute_reply": "2024-08-05T13:02:42.153773Z"
        },
        "trusted": true,
        "id": "Uly066G3LvBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}